{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Images/1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC5JMu6sxets"
   },
   "source": [
    "![](Images/3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqijN8wvAsa2"
   },
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTxkLbgvASNA"
   },
   "outputs": [],
   "source": [
    "#!pip install pvlib\n",
    "#!pip install pandas\n",
    "#!pip install ipywidgets\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pvlib\n",
    "from datetime import datetime, timedelta\n",
    "from pvlib.iotools import read_epw\n",
    "import gym\n",
    "from gym import spaces\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame\n",
    "import sys\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiAL80dgzthz"
   },
   "source": [
    "![](Images/4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8G3FxsPAxAl"
   },
   "source": [
    "LOAD WEATHER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Z6XZE7vWPPc",
    "outputId": "14e37dea-82c3-4ef0-c846-5950c1eb2bff"
   },
   "outputs": [],
   "source": [
    "# Read the EPW file\n",
    "weather_data, meta = read_epw(\"istanbulWeather.epw\")\n",
    "\n",
    "# Preview the data\n",
    "print(weather_data.head())\n",
    "print(weather_data.columns.tolist())\n",
    "\n",
    "# Access dry bulb temperature (°C)\n",
    "temps = weather_data[\"temp_air\"]\n",
    "\n",
    "# Example: Print first 5 timestamps and temps\n",
    "for i, (time, temp) in enumerate(temps.items()):\n",
    "    if i >= 50:\n",
    "        break\n",
    "    print(f\"{i}: {temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTWo5foxp_A3"
   },
   "source": [
    "![](Images/7.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kor-E1i6ppJ-",
    "outputId": "07c3c863-35af-4b97-be45-92d3e07ef383"
   },
   "outputs": [],
   "source": [
    "print(len(temps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lim81QP8A9jK"
   },
   "source": [
    "> SET UP THE ROOM CONSTANTS AND GLOBAL VARIABLES\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8Fd2NFaABqr"
   },
   "outputs": [],
   "source": [
    "SURFACE_AREA = 9 #m^2\n",
    "VOLUME = 27 #m^3\n",
    "HEATER_OUTPUT = 1000 #watt\n",
    "AIR_HEAT_CAPACITY = 718 # J/kg.Kelvin\n",
    "AIR_DENSITY = 1.3 #kg/m^3\n",
    "U_CEILING = 0.4\n",
    "U_FLOOR = 0.5\n",
    "U_WALL = 0.6\n",
    "HEAT_ON    = 0\n",
    "COOL_ON    = 1\n",
    "THERM_OFF  = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5EQHlJDh0FI"
   },
   "outputs": [],
   "source": [
    "daily_logs = defaultdict(lambda: {\n",
    "    'time': [],\n",
    "    'tto': [],\n",
    "    'room_temp': [],\n",
    "    'outside_temp': [],\n",
    "    'reward': []\n",
    "})\n",
    "Q = defaultdict(lambda: np.zeros(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEyNoK3EF22d"
   },
   "source": [
    "![](Images/8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptnzAEvUBDuu"
   },
   "source": [
    "CALCULATE HEAT LOSS AND CHANGE IN TEMPRATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMsnkccKBADw"
   },
   "outputs": [],
   "source": [
    "def calculate_heat_transfer(temp_outside, temp_inside):\n",
    "    temp_diff = temp_inside - temp_outside\n",
    "    heat_transfer_ceiling =  U_CEILING * SURFACE_AREA *(temp_diff)\n",
    "    heat_transfer_floor = U_FLOOR * SURFACE_AREA *(temp_diff)\n",
    "    heat_transfer_wall = U_WALL * 4 * SURFACE_AREA *(temp_diff)\n",
    "    heat_transfer_total = heat_transfer_ceiling + heat_transfer_floor + heat_transfer_wall\n",
    "    return heat_transfer_total\n",
    "\n",
    "def calculate_change_in_temp(heat_change):\n",
    "  change_in_temp = -(heat_change * 60)/(AIR_HEAT_CAPACITY * AIR_DENSITY * VOLUME)\n",
    "  return change_in_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IlzyQKmCThs"
   },
   "source": [
    "SET UP HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttxMY6rPppJ_"
   },
   "outputs": [],
   "source": [
    "def reset_plot_variables():\n",
    "  global daily_logs, Q\n",
    "  daily_logs.clear()\n",
    "  Q.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3Zg2PY-ppJ_"
   },
   "outputs": [],
   "source": [
    "def save_model(q_table, predictor,logs, filename=\"model.pkl\"):\n",
    "    data = {\n",
    "        \"q_table\": q_table,\n",
    "        \"predictor\": predictor,\n",
    "        \"daily_logs\": logs\n",
    "    }\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbWpG9MJppJ_"
   },
   "outputs": [],
   "source": [
    "def load_model(filename=\"model.pkl\"):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        q_table = defaultdict(lambda: np.zeros(3), data[\"q_table\"])\n",
    "        predictor = data[\"predictor\"]\n",
    "        daily_logs = defaultdict(lambda: {\n",
    "    'time': [],\n",
    "    'tto': [],\n",
    "    'room_temp': [],\n",
    "    'outside_temp': [],\n",
    "    'reward': []\n",
    "}, data[\"daily_logs\"])\n",
    "\n",
    "    return q_table, predictor, daily_logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHwWYNAwCeZU"
   },
   "outputs": [],
   "source": [
    "def get_outside_temp(time):\n",
    "    \"\"\"Given a global minute count (0 to ~525600), return outside temperature.\"\"\"\n",
    "    H = len(temps)\n",
    "    hour = (time // 60) % H             # wrap around\n",
    "    next_hour = (hour + 1) % H\n",
    "    frac = time % 60\n",
    "    delta = (temps.iloc[next_hour] - temps.iloc[hour]) / 60\n",
    "\n",
    "    return round(temps.iloc[hour] + delta * frac, 0)\n",
    "\n",
    "def get_time_bin(time, interval_minutes=15):\n",
    "    \"\"\"\n",
    "    Given a global minute count (0 to ~525600), return time bin string like '08:15'.\n",
    "    \"\"\"\n",
    "    minute_of_day = time % 1440  # 1440 minutes in a day\n",
    "    bin_minute = (minute_of_day // interval_minutes) * interval_minutes\n",
    "    return f\"{bin_minute // 60:02d}:{bin_minute % 60:02d}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIIsOkIjeYIe"
   },
   "outputs": [],
   "source": [
    "def is_working_hours(total_minutes):\n",
    "    \"\"\"Check if the current minute of the year is within 08:00–18:00 of the current day.\"\"\"\n",
    "    minute_of_day = total_minutes % 1440\n",
    "    return 480 <= minute_of_day < 1080\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjPWdeG6ppJ_"
   },
   "outputs": [],
   "source": [
    "def print_q_table():\n",
    "    global Q\n",
    "    print(f\"{'State (RoomTemp, TTO, OutTemp)':40s} | {'Heat On':>8s} | {'Cool On':>8s} | {'Off':>8s}\")\n",
    "    print(\"-\" * 75)\n",
    "    for state, actions in Q.items():\n",
    "        rt, tto, ot = state\n",
    "        heat_on, cool_on, off = actions\n",
    "        print(f\"({rt:5.1f}, {tto:5.1f}, {ot:5.1f})\".ljust(40),\n",
    "              f\"| {heat_on:8.2f} | {cool_on:8.2f} | {off:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJVmPkLVR5ad"
   },
   "source": [
    "BAYSEAN OCCUPANCY PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igocLFeDOolV"
   },
   "outputs": [],
   "source": [
    "class BayesianOccupancyPredictor:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store probabilities and experience count for each time slot (e.g. \"08:00\", \"08:15\")\n",
    "        self.occupancy_probs = {}\n",
    "        self.experience_counts = {}\n",
    "\n",
    "    def initialize_slot(self, time_slot):\n",
    "        \"\"\"Initialize the time slot if not already present.\"\"\"\n",
    "        if time_slot not in self.occupancy_probs:\n",
    "            self.occupancy_probs[time_slot] = {\n",
    "                'occupied': 0.5,       # Initial prior (50/50)\n",
    "                'not_occupied': 0.5\n",
    "            }\n",
    "            self.experience_counts[time_slot] = 0\n",
    "\n",
    "    def update(self, time_slot, observed_occupied):\n",
    "        \"\"\"Update the probabilities based on a new observation.\"\"\"\n",
    "        self.initialize_slot(time_slot)\n",
    "\n",
    "        prob = self.occupancy_probs[time_slot]\n",
    "        expc = self.experience_counts[time_slot]\n",
    "        expc_prime = expc + 1\n",
    "\n",
    "        if observed_occupied:\n",
    "            prob['occupied'] = (prob['occupied'] * expc + 1) / expc_prime\n",
    "            prob['not_occupied'] = (prob['not_occupied'] * expc) / expc_prime\n",
    "        else:\n",
    "            prob['occupied'] = (prob['occupied'] * expc) / expc_prime\n",
    "            prob['not_occupied'] = (prob['not_occupied'] * expc + 1) / expc_prime\n",
    "\n",
    "        self.experience_counts[time_slot] = expc_prime\n",
    "\n",
    "    def predict(self, time_slot):\n",
    "        \"\"\"Return the current probability of occupancy.\"\"\"\n",
    "        self.initialize_slot(time_slot)\n",
    "        return self.occupancy_probs[time_slot]['occupied']\n",
    "\n",
    "    def print_state(self):\n",
    "        \"\"\"Print all learned occupancy probabilities.\"\"\"\n",
    "        for slot, probs in sorted(self.occupancy_probs.items()):\n",
    "            print(f\"{slot}: P(occupied)={probs['occupied']:.3f}, P(not_occupied)={probs['not_occupied']:.3f}\")\n",
    "\n",
    "    def calculate_tto(self, current_time, threshold=0.7, lookahead_bins=8, bin_interval=15):\n",
    "      \"\"\"Calculate the time to occupancy\"\"\"\n",
    "      for i in range(1, lookahead_bins + 1):\n",
    "          future_time = current_time + i * bin_interval  # Just add minutes\n",
    "          time_bin = get_time_bin(future_time)           # Convert to 'HH:MM' bin\n",
    "          prob = self.predict(time_bin)                  # Lookup predicted occupancy\n",
    "          if prob >= threshold:\n",
    "              return i * bin_interval\n",
    "      return lookahead_bins * bin_interval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mygWIXmOylue"
   },
   "source": [
    "![](Images/5.jpg)\n",
    "![](Images/6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9pEbQk6h8Ao"
   },
   "source": [
    "DEFINE THE ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFFnMAx0ku41"
   },
   "outputs": [],
   "source": [
    "class MyHvacEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(MyHvacEnv, self).__init__()\n",
    "\n",
    "        # 1. Define action space\n",
    "        self.action_space = spaces.Discrete(3)  # 0=Heaton, 1=Cool on, 2=thermostatoff\n",
    "\n",
    "        # 2. Define observation space [rt, tto, ot]\n",
    "        # rt ∈ [-8, 32], tto ∈ [0, 120], ot ∈ [-8, 32]\n",
    "        self.bayesianOccupancyPredictor = BayesianOccupancyPredictor()\n",
    "        self.low = np.array([-8.0, 0.0, -8.0], dtype=np.float32)\n",
    "        self.high = np.array([32, 120.0, 32], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(self.low, self.high, dtype=np.float32)\n",
    "        self.time = 0\n",
    "\n",
    "        # 3. Internal state variables\n",
    "\n",
    "        self.state,_  = self.reset()\n",
    "        self.rt = self.state[0]\n",
    "        self.tto = self.state[1]\n",
    "        self.ot = self.state[2]\n",
    "        self.step_count = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.bayesianOccupancyPredictor.update(get_time_bin(0), is_working_hours(0))\n",
    "        super().reset(seed=seed)\n",
    "        # Initialize state: [room_temp, time_to_occupancy, outside_temp]\n",
    "        ot = rt = get_outside_temp(self.time)\n",
    "        tto = self.bayesianOccupancyPredictor.calculate_tto(self.time)\n",
    "        self.state = np.array([rt,tto,ot], dtype=np.float32)\n",
    "        self.step_count = 0\n",
    "        self.time = 0\n",
    "        return self.state, {}  # observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.time += 1\n",
    "        self.bayesianOccupancyPredictor.update(\n",
    "        get_time_bin(self.time),\n",
    "        is_working_hours(self.time)\n",
    "    )\n",
    "        rt, tto, ot = self.state\n",
    "        conduction = calculate_heat_transfer(ot, rt)\n",
    "        heat_change = conduction\n",
    "\n",
    "        if action == HEAT_ON:\n",
    "            heat_change = conduction - HEATER_OUTPUT\n",
    "        elif action == COOL_ON:\n",
    "            heat_change = conduction + HEATER_OUTPUT\n",
    "\n",
    "        change_in_T = calculate_change_in_temp(heat_change)\n",
    "\n",
    "        self.rt = np.clip(round(rt + change_in_T, 0), self.low[0], self.high[0])\n",
    "        self.tto = self.bayesianOccupancyPredictor.calculate_tto(self.time)\n",
    "        self.ot = get_outside_temp(self.time)\n",
    "        reward = self.get_reward(action)\n",
    "        # Update state\n",
    "        self.state = np.array([self.rt, self.tto, self.ot], dtype=np.float32)\n",
    "        self.step_count += 1\n",
    "        terminated = self.time % 1440 == 0\n",
    "        truncated = False\n",
    "\n",
    "        return self.state, reward, terminated, truncated, {}\n",
    "\n",
    "    def get_reward(self,action):\n",
    "      rt, tto, ot = self.state\n",
    "      occupied = is_working_hours(self.time)\n",
    "      setpoint = 23.0\n",
    "      threshold = 2\n",
    "      reward = 0\n",
    "      if occupied and abs(rt - setpoint) <= threshold :\n",
    "         reward = 30\n",
    "      elif occupied and abs(rt - setpoint) > threshold :\n",
    "         reward = -15\n",
    "      elif (tto>=60 and (action == HEAT_ON or action == COOL_ON)) :\n",
    "        reward = -10\n",
    "      elif(action == HEAT_ON and (rt > setpoint or ot > setpoint)):\n",
    "        reward = -7\n",
    "      elif(action == COOL_ON and (rt < setpoint or ot < setpoint)):\n",
    "        reward = -7\n",
    "      else:\n",
    "        reward = 0\n",
    "\n",
    "      return reward\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKbTa__Y0XeB"
   },
   "source": [
    "![](Images/9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xp5mwcupppJ_"
   },
   "outputs": [],
   "source": [
    "def train(days, years):\n",
    "  global Q\n",
    "  env = MyHvacEnv()\n",
    "  action_size = env.action_space.n\n",
    "\n",
    "  import random\n",
    "\n",
    "  # Hyperparameters\n",
    "  alpha = 0.1        # learning rate\n",
    "  gamma = 0.99       # discount factor\n",
    "  epsilon = 1.0      # exploration rate\n",
    "  epsilon_decay = 0.5\n",
    "  for ep in range(years):\n",
    "    state, _ = env.reset()\n",
    "    epsilon *= epsilon_decay\n",
    "    for j in range(days):\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            state_key = tuple(state)\n",
    "\n",
    "            # Epsilon-greedy action selection\n",
    "            if state_key not in Q:\n",
    "                Q[state_key] = np.zeros(env.action_space.n)\n",
    "            if random.random() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(Q[state_key])\n",
    "\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            next_state_key = tuple(next_state)\n",
    "            if next_state_key not in Q:\n",
    "                 Q[next_state_key] = np.zeros(action_size)\n",
    "            # Update Q-table\n",
    "            if total_reward <-500000:\n",
    "              truncated = True\n",
    "            done = terminated or truncated\n",
    "            best_next_action = np.argmax(Q[next_state_key])\n",
    "            td_target = reward + gamma * Q[next_state_key][best_next_action]\n",
    "            td_error = td_target - Q[state_key][action]\n",
    "\n",
    "            Q[state_key][action] += alpha * td_error\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            # Log after step\n",
    "            if(env.time % 15 == 0):\n",
    "              if ep == years-1:\n",
    "                day = env.time // 1440\n",
    "                minute_of_day = env.time % 1440\n",
    "\n",
    "                daily_logs[day]['time'].append(minute_of_day)\n",
    "                daily_logs[day]['room_temp'].append(env.rt)\n",
    "                daily_logs[day]['outside_temp'].append(env.ot)\n",
    "                daily_logs[day]['reward'].append(reward)\n",
    "                daily_logs[day]['tto'].append(env.tto)\n",
    "        if(j%365 == 0):\n",
    "          print(f\"Year {ep+1}, Total reward: {total_reward}\")\n",
    "  save_model(dict(Q), env.bayesianOccupancyPredictor, dict(daily_logs), \"Models/model4.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qny3olckppJ_",
    "outputId": "218930cc-1def-42f8-bff9-315e001244fe"
   },
   "outputs": [],
   "source": [
    "reset_plot_variables()\n",
    "train(365,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYLC-ROIppJ_"
   },
   "outputs": [],
   "source": [
    "Q,_,logs = load_model(\"Models/model4.pkl\") #best model is model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7TXBH2UppJ_",
    "outputId": "22b2101f-d442-4ec5-ba86-3808d8f766bb"
   },
   "outputs": [],
   "source": [
    "print(len(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IanxEqOgtVO"
   },
   "source": [
    "PLOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbExqdwYppJ_",
    "outputId": "a65c7a72-d868-4c11-8425-d44adb5c1ecd"
   },
   "outputs": [],
   "source": [
    "# Total reward per day\n",
    "daily_reward_sums = {day: sum(log['reward']) for day, log in logs.items()}\n",
    "\n",
    "# Aggregate by month (day // 30)\n",
    "monthly_reward_sums = defaultdict(int)\n",
    "for day, total in daily_reward_sums.items():\n",
    "    month = day // 30\n",
    "    monthly_reward_sums[month] += total\n",
    "\n",
    "# Plot daily reward\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(daily_reward_sums.keys(), daily_reward_sums.values())\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Reward per Day\")\n",
    "plt.show()\n",
    "\n",
    "# Plot monthly reward\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(monthly_reward_sums.keys(), monthly_reward_sums.values())\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Reward per Month\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8f_ER-9ppJ_"
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Interactive Day Picker Plot\n",
    "# -------------------------------\n",
    "def plot_day(daily_logs, day):\n",
    "    if day not in daily_logs:\n",
    "        print(f\"Day {day} not found.\")\n",
    "        return\n",
    "\n",
    "    data = daily_logs[day]\n",
    "    time_raw = [t for t in data['time'] if t % 15 == 0]\n",
    "    idxs = [i for i, t in enumerate(data['time']) if t % 15 == 0]\n",
    "\n",
    "    tto = [data['tto'][i] for i in idxs]\n",
    "    rt = [data['room_temp'][i] for i in idxs]\n",
    "    ot = [data['outside_temp'][i] for i in idxs]\n",
    "    reward = [data['reward'][i] for i in idxs]\n",
    "    cumulative_reward = [sum(reward[:i+1]) for i in range(len(reward))]\n",
    "\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\n",
    "    hours = [f\"{t // 60:02d}:00\" for t in range(0, 1440, 60)]\n",
    "    xticks = [i for i, t in enumerate(time_raw) if t % 60 == 0]\n",
    "\n",
    "    ax[0].plot(tto, label='Predicted Occupancy')\n",
    "    ax[0].set_ylabel(\"Time to Occupancy.\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(rt, label='Indoor Temp')\n",
    "    ax[1].plot(ot, label='Outdoor Temp', linestyle='--')\n",
    "    ax[1].set_ylabel(\"Temperature (°C)\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].plot(reward, label='Reward', color='green')\n",
    "    ax[2].set_ylabel(\"Reward\")\n",
    "    ax[2].legend()\n",
    "\n",
    "    ax[3].plot(cumulative_reward, label='Cumulative Reward', color='orange')\n",
    "    ax[3].set_ylabel(\"Cumulative Reward\")\n",
    "    ax[3].set_xlabel(\"Time (hour)\")\n",
    "    ax[3].legend()\n",
    "\n",
    "    plt.xticks(xticks, hours, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNDd_3KZppJ_",
    "outputId": "12bbc6a1-1c98-4e0d-db5f-1109f45b312c"
   },
   "outputs": [],
   "source": [
    "plot_day(logs, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3p6NN5bVppJ_"
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Interactive Day Picker Widget\n",
    "# -------------------------------\n",
    "\n",
    "def interactive_day_plot(daily_logs):\n",
    "    max_day = max(daily_logs.keys())\n",
    "\n",
    "    day_selector = widgets.IntSlider(value=0, min=1, max=max_day, step=1, description='Day:')\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def update_plot(change):\n",
    "        with output:\n",
    "            output.clear_output(wait=True)\n",
    "            plot_day(daily_logs, day_selector.value)\n",
    "\n",
    "    day_selector.observe(update_plot, names='value')\n",
    "\n",
    "    display(day_selector, output)\n",
    "    update_plot(None)  # initial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a86ea8ea7d5d42088902f77354d4edbb",
      "eaf3f2799b464a8aafb4b24f3625de61"
     ]
    },
    "id": "16V1YJZ-ppJ_",
    "outputId": "656efdf9-8074-462f-9866-e9571965e7e5"
   },
   "outputs": [],
   "source": [
    "interactive_day_plot(logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3bNA07fppKA"
   },
   "source": [
    "SIMULATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_day(day):\n",
    "    q_table, predictor, daily_logs = load_model(\"model3.pkl\")\n",
    "    env = MyHvacEnv()\n",
    "    env.bayesianOccupancyPredictor = predictor\n",
    "    state, _ = env.reset()\n",
    "    env.time = day * 1440 + 1\n",
    "    initial_temp = get_outside_temp(env.time)\n",
    "    state[0] = initial_temp   # rt\n",
    "    state[2] = initial_temp   # ot\n",
    "    state[1] = predictor.calculate_tto(env.time)  # tto\n",
    "    env.state = np.array([state[0], state[1], state[2]], dtype=np.float32)\n",
    "\n",
    "    pygame.init()\n",
    "    WIDTH, HEIGHT = 800, 600\n",
    "    screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "    pygame.display.set_caption(\"Q-Table Day Simulation\")\n",
    "    font = pygame.font.SysFont(None, 28)\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    running = True\n",
    "    paused = False\n",
    "    step_index = 0\n",
    "\n",
    "    def temp_color(temp):\n",
    "        if temp < 20:\n",
    "            return (0, 0, 255)\n",
    "        elif temp > 25:\n",
    "            return (255, 0, 0)\n",
    "        else:\n",
    "            return (0, 255, 0)\n",
    "\n",
    "    def draw(state, action, reward):\n",
    "        screen.fill((245, 245, 245))\n",
    "        rt, tto, ot = state\n",
    "\n",
    "        ot_size = np.interp(ot, [env.low[2], env.high[2]], [100, 400])\n",
    "        ot_color = temp_color(ot)\n",
    "        ot_rect = pygame.Rect(WIDTH//2 - ot_size//2, HEIGHT//2 - ot_size//2, ot_size, ot_size)\n",
    "        pygame.draw.rect(screen, ot_color, ot_rect, width=4)\n",
    "\n",
    "        rt_size = np.interp(rt, [env.low[0], env.high[0]], [50, ot_size-20])\n",
    "        rt_color = temp_color(rt)\n",
    "        rt_rect = pygame.Rect(WIDTH//2 - rt_size//2, HEIGHT//2 - rt_size//2, rt_size, rt_size)\n",
    "        pygame.draw.rect(screen, rt_color, rt_rect)\n",
    "\n",
    "        occ = is_working_hours(env.time)\n",
    "        tri_color = (255, 165, 0) if occ else (128, 128, 128)\n",
    "        cx, cy = WIDTH//2, HEIGHT//2\n",
    "        size = rt_size / 3\n",
    "        points = [\n",
    "            (cx, cy - size / 2),\n",
    "            (cx - size / 2, cy + size / 2),\n",
    "            (cx + size / 2, cy + size / 2)\n",
    "        ]\n",
    "        pygame.draw.polygon(screen, tri_color, points)\n",
    "\n",
    "        labels = [\n",
    "            f\"Day: {day}\",\n",
    "            f\"Time: {env.time//60 % 24:02d}:{env.time % 60:02d}\",\n",
    "            f\"Room Temp: {env.rt:.1f}°C\",\n",
    "            f\"Outside Temp: {env.ot:.1f}°C\",\n",
    "            f\"TTO: {env.tto:.1f} min\",\n",
    "            f\"Action: {['Heat On','Cool On','Off'][action]}\",\n",
    "            f\"Reward: {reward:.1f}\",\n",
    "            f\"Occupied: {'Yes' if occ else 'No'}\"\n",
    "        ]\n",
    "        for i, txt in enumerate(labels):\n",
    "            surf = font.render(txt, True, (0, 0, 0))\n",
    "            screen.blit(surf, (40, 40 + i * 30))\n",
    "\n",
    "        pygame.display.flip()\n",
    "\n",
    "    while running:\n",
    "        clock.tick(15 if not paused else 3)\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_SPACE:\n",
    "                    paused = not paused\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    day += 1\n",
    "                    state, _ = env.reset()\n",
    "                    env.time = day * 1440\n",
    "                    new_temp = get_outside_temp(env.time)\n",
    "                    state[0] = new_temp\n",
    "                    state[2] = new_temp\n",
    "                    state[1] = predictor.calculate_tto(env.time)\n",
    "                    env.state = np.array([state[0], state[1], state[2]], dtype=np.float32)\n",
    "                    step_index = 0\n",
    "                elif event.key == pygame.K_LEFT:\n",
    "                    day = max(0, day - 1)\n",
    "                    state, _ = env.reset()\n",
    "                    env.time = day * 1440\n",
    "                    new_temp = get_outside_temp(env.time)\n",
    "                    state[0] = new_temp\n",
    "                    state[2] = new_temp\n",
    "                    state[1] = predictor.calculate_tto(env.time)\n",
    "                    env.state = np.array([state[0], state[1], state[2]], dtype=np.float32)\n",
    "                    step_index = 0\n",
    "\n",
    "        if not paused and running:\n",
    "            tto_now = predictor.calculate_tto(env.time)\n",
    "            current_rt = env.rt\n",
    "            current_ot = env.ot\n",
    "            state = np.array([current_rt, tto_now, current_ot], dtype=np.float32)\n",
    "            state_key = (float(state[0]), float(state[1]), float(state[2]))\n",
    "\n",
    "            if state_key not in q_table:\n",
    "                print(\"Missing key in Q-table:\", state_key)\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = int(np.argmax(q_table[state_key]))\n",
    "\n",
    "            state, reward, terminated, truncated, _ = env.step(action)\n",
    "            draw(state, action, reward)\n",
    "            step_index += 1\n",
    "\n",
    "            if step_index >= 1440 or terminated:\n",
    "                paused = True\n",
    "\n",
    "    pygame.quit()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_day(55)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
